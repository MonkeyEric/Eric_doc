## 1.传输优化
主机A需要给主机B传输一份100GB的数据，可以做哪些传输优化？
1. 数据打包压
2. 数据分片，同步传输
4. 增大传输带宽，网络端口聚合
[学习链接](https://zhuanlan.zhihu.com/p/99017933)

## 2.防火墙配置脚本 
写一个防火墙配置脚本，只允许远程主机访问本机的80端口
```shell
Iptables –A INPUT –p tcp –dport 80 –j ACCEPT

Iptables –A INPUT –s0.0.0.0/0 –j DROP
```

## 3.获取两个list的交集
*方法一*
```python
a = [2,3,4,5]
b = [2,5,8]
tmp = [val for val in a if val in b]
print(tmp)
```
*方法二*
```python
a = [2,3,4,5]
b = [2,5,8]
print(list(set(a).intersection(set(b))))
```
## 4. 获取两个list的并集
```python
a = [2,3,4,5]
b = [2,5,8]
print(list(set(a).union(set(b))))
```
## 5. 获取两个list的差集
```python
a = [2,3,4,5]
b = [2,5,8]
print(list(set(a).difference(set(b))))
```

## 6. 简述软连接和硬链接的区别？
* 软链接是指创建一个新的文件，block里存放的是被链接文件的文件名指向，软链接的inode与源文件的inode不同，将源文件删除，然后重建，改变了inode，软链接文件仍然有效。
* 硬链接是创建一个新的文件名，将它的inode指向源文件的inode，所以硬链接的inode和源文件是相同的，源文件被删除后，硬链接仍然可以有效。
## 7. 简述一些DNS的解析过程
1. 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。
2. 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。
3. 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。
4. 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。
5. 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。
6. 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。

从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。

## 8.写一个脚本进行Nginx日志统计
写一个脚本进行Nginx日志统计，得到访问ip最多的前10个（Nginx日志路径：/nginx/default/access.log）
```python
# 统计ip,url,code的次数，并且生成字典
def log_analysis(log_file, top_num=10):
    path = log_file
    log_read = open(path, 'r')

    log_dict = {}

    while True:
        line = log_read.readline()
        if line == '':
            break
        nodes = line.split()

        # {(ip,url,code):count}当做字典的key
        # print 'ip:%s, url:%s, code:%s' % (nodes[0],nodes[6],nodes[8])

        # 拼凑字典，如果不存在赋值为1，如果存在则+1

        ip,a_time,a_method, url, code = nodes[0],nodes[3].replace('[',''), nodes[5],nodes[6], nodes[8]
        if (ip, url, code) not in log_dict:
            log_dict[(ip, url, code)] = 1
        else:
            log_dict[(ip, url, code)] = log_dict[(ip, url, code)] + 1
    # 关闭文件句柄
    log_read.close()
    # 对字典进行排序
    # print log_dict
    # ('111.37.21.148', '/index', '200'): 2
    rst_list = log_dict.items()
    for j in range(10):
        # 冒泡法根据rst_list中的count排序，找出访问量最大的10个IP
        for i in range(0, len(rst_list) - 1):
            if rst_list[i][1] > rst_list[i + 1][1]:
                temp = rst_list[i]
                rst_list[i] = rst_list[i + 1]
                rst_list[i + 1] = temp

    need_list = rst_list[-1:-top_num - 1:-1]
    # 打印出top 10访问日志
    print(need_list)


# 函数入口
if __name__ == '__main__':
    # nginx日志文件
    file1 = 'access.log'
    # top_num 表示去top多少个
    top_n = 10
    log_analysis(file1, top_n)
```
## 9. 判断字符串是否以"this"开头 
strA=‘this is string example…….wow!!!’,判断字符串strA是否以”this”开头
```python
# coding:utf-8
strA = 'this is string example…….wow!!!'
print(strA.startswith('this'))

```
## 10. 读取100G的文件
一个大小为100G的文件et_log.txt，要读取文件中的内容，写出具体过程代码
## 11. 比较复杂度
Alist=[1,2,3],Bset={1,2,3}  
* 从Alist和Bset中查找4，最坏时间复杂度哪个大？
* 向Alist和Bset中插入4，最坏时间复杂度哪个大？
1. 对于查找，列表和集合的最坏时间复杂度都是O(n)，所以一样的。
2. 列表操作插入的最坏时间复杂度为o(n), 集合为o(1)，所以Alist大。set是哈希表所以操作的复杂度基本上都是o(1)。
## 12. os.path和sys.path的区别？

1. os.path 主要是用于对系统路径文件的操作。
2. sys.path 主要是对 Python 解释器的系统环境参数的操作（动态的改变 Python 解释器搜索路径）。
## 13.你在编程过程中遇到过哪些Exception？
什么情况下会产生这些exception？

	*  NameError  尝试访问一个未申明的变量        >>v
	*  ZeroDivisionError：除数为0   >>v=2/0
	*  SyntaxError:语法错误  >>int int
	*  IndexError：索引超出范围    >>list=[2]      >>list[3]
	*  KeyError:字典关键字不存在   dic={"1":"yes","2":"no"}  >>Dic['3']
	*  IoError：输入输出错误
	*  AttributeError：访问未知对象属性
	*  ValuError：数值错误      >>int("b")

## 13. 简述Python中使用线程的几种方式？
[网址链接](https://www.cnblogs.com/lxy0/p/11403555.html)
## 14. 填空题

```python
a = [1]
b = a
a.append(2)
print("b", b)
# 1)此时b的值为：[1,2]
b.append(3)
print("a", a)
# 2)此时a的值为：[1,2,3]
a = [2, 3]


def aaa(b):
    b.append(4)
    print("b", b)


#        3)此时b的值为：[1,2,3,4]


def bbb(b):
    b = 5
    print("bbb", b)


#        4)此时b的值为:______________

aaa(b)
print(b)
# 5)此时b的值为：[1,2,3,4]

bbb(b)
print(b)
# 6)此时b的值为：[5] and [1,2,3,4]

```

## 15. 写出下列编程的结果
```python
def bar(n):
    m = n
    while True:
        m += 1
        yield m


b = bar(5)

print(next(b))  # 6

```
## 16. 写出下面编程的结果
```python
def dec(f):
    n = 3

    def wrapper(*args, **kwargs):
        return f(*args, **kwargs) * n

    return wrapper


@dec
def foo(n):
    return n * 2


print(foo(3))  # 18

```
## 17. 将python的list删除掉重复的元素
```python
# 方法1
a=[1,2,4,2,4,5,6,5,7,8,9,0]
b={}
b=b.fromkeys(a)
c=list(b.keys())
print(c)
# 方法2 使用set
# 方法3 使用append 或者count来循环删除或者添加
```
## 18. 描述数组与链表各自的特点以及他们的优缺点？

	* 在存储位置上：               
      数组逻辑上相邻的元素在物理存储位置上也相邻，而链表不一定；
	* 在存储空间上：               
      链表存放的内存空间可以是连续的，也可以是不连续的，数组则是连续的一段内存空间，一般情况下存放相同多的数据数组占用较小的内存，而链表还需要存放其前驱和后继的空间
	* 长度的可变性：            
      链表的长度是按照实际需要可以伸缩的，而数组的长度是在定义时要给定的，如果存放的数据个数超过了数组的初始大小，则会出现溢出的现象。
	* 按序号查找时，           
       数组可以随机访问，时间复杂度O（1），而链表不支持随机访问，平均需要O(n)
	* 按值查找时                   
       若数组无需，数组和链表时间复杂度均为O(1)，但是当数组有序是，可以采用折半查找将时间复杂度降为O（logn）
	* 插入和删除时
       数组平均需要移动n/2个元素，而链表只需修改指针即可；
	* 空间分配方面：                 
       数组在静态存储分配情形下，存储元素数量受限制，动态存储分配情形下，虽然存储空间可以扩充，但需要移动大量元素，导致操作效率降低，而且如果内存中没有更大块连续存储空间将导致分配失败，即数组从栈中分配空间，

## 19. 将字符串 'abcdefg' 倒序，至少三种方法
```python
# 方法一
a = 'abcdefgh'
print(a[::-1])

# 方法二
b = list(a)
b.reverse()
print(''.join(b))

# 方法三
c = len(a) - 1
str_1 = []
while (c >= 0):
    str_1.append(a[c])
    c -= 1
print(''.join(str_1))

```
## 20. 解释什么是栈溢出，在什么情况下可能出现
## 21. 现在，有一行括号序列字符串，请写出一段代码检查这行括号是否配对，例如：
    [(])   F
    (])   F
    ([[]()])    T

## 22. 简述LVS的工作模式和调度算法，大并发环境推荐结构
## 23. 简单介绍一下你使用过的服务器监控软件，并简要说明下它们和自己的特点，介绍下常用的监控指标，查看当前Linux系统的状态，如CPU使用、内存使用、负载情况等，查看占用内存最大的5个进程
## 24. 编写个shell脚本将/logs目录下3天前的文件转移到/tmp目录下
## 25.sed将文件test.txt中的所有“/opt/eastmoney”改为“/root/EastMoney”。并删除所有空行。
## 26. 用 Python实现斐波拉契数列
## 27. 给定三角形的坐标，用Python如何求三角形的面积。
## 28. 如果想知道一个函数的执行时间，应该怎么样做？
## 29. 你对自己写的代码如何做单元测试？
## 30. 遇到过编码问题吗？请简述一些Python中如何规范编码？
## 31. 你使用什么进行代码版本管理，你都用过哪些版本，过程是怎样的？多人协作的情况下，你对项目的版本管是怎么样的？
## 32. Python是如何进行内存管理的？
## 33. Python是如何进行内存管理的？
## 34. 当多个线程都修改某一个共享数据的时候，需要进行同步控制，请使用Python代码实现多线程互斥锁同步的案例。
## 35. 给定某一文件夹路径，输出该文件夹下文件路径及其子文件中文件路径
## 36. 现有一个函数：
```python
def work(seq):
    # do something
    print(seq)
    # do something
```
1. 请分别使用多线程、多进程调用该函数
2. 简述Lock、Rlock的区别
3. 简述Queue.Queue能在多进程中使用吗？


## 37. 计算机网络协议与编程
    1. HTTP、HTTPs、TCP、UDP、IP分别是TCP/IP协议栈的哪一层协议
    2. 简述你常用的HTTP头域和其作用
    3. 网络编程中TCp服务器端编程模型
## 38. zabbix使用教程  [链接](https://www.cnblogs.com/clsn/p/7885990.html)

## 39. TCP/IP三次握手、四次握手过程
    TCP/IP
    简述TCP三次握手的过程？
    答：在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认。第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态。第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。完成三次握手，客户端与服务器开始传送数据简版：首先A向B发SYN（同步请求），然后B回复SYN+ACK（同步请求应答），最后A回复ACK确认，这样TCP的一次连接（三次握手）的过程就建立了。
    
    为什么连接的时候是三次握手，关闭的时候却是四次握手？
    这是因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。
    但是关闭连接时，当Client端发送FIN报文仅仅表示它不再发送数据了但是还能接收数据，Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，“你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

## 40. MySQL主从复制
主从复制的原理如下：
主库开启binlog功能并授权从库连接主库，从库通过change master得到主库的相关同步信息,然后连接主库进行验证，主库IO线程根据从库slave线程的请求，从master.info开始记录的位置点向下开始取信息，同时把取到的位置点和最新的位置与binlog信息一同发给从库IO线程，从库将相关的sql语句存放在relay-log里面，最终从库的sql线程将relay-log里的sql语句应用到从库上，至此整个同步过程完成，之后将是无限重复上述过程

    完整步骤如下：
    1. 主库开启binlog功能，并进行全备，将全备文件推送到从库服务器上
    2. show master status\G 记录下当前的位置信息及二进制文件名
    3. 登陆从库恢复全备文件
    4. 执行change master to 语句
    5. 执行start slave and show slave status\G

## 41. 调取后端接口过慢的解决思路
1. 问清楚反应的人哪个服务应用或者页面调取哪个接口慢，叫他把页面或相关的URL发给你， 
2. 首先，最直观的分析就是用浏览器按F12，看下是哪一块的内容过慢（DNS解析、网络加载、大图片、还是某个文件内容等），如果有，就对症下药去解决（图片慢就优化图片、网络慢就查看内网情况等）。
3. 其次，看后端服务的日志，其实大多数的问题看相关日志是最有效分析，最好用tail -f 跟踪一下日志，当然你也要点击测试来访问接口日志才会打出来。
4. 最后，排除sql，，找到sql去mysql执行一下，看看时间是否很久，如果很久，就要优化SQL问题了，expain一下SQL看看索引情况啥的，针对性优化。数据量太大的能分表就分表，能分库就分库。如果SQL没啥问题，那可能就是写的逻辑代码的问题了，一行行审代码，找到耗时的地方改造，优化逻辑。

## 42. 常用高可用技术
* Keepalived：Keepalived是一个保证集群高可用的服务软件，用来防止单点故障，使用VRRP协议实现。在master和backup之间通过master主动降低自己的权值或者backup检测到master出现故障时，backup将会接管master的工作，继续服务。
* HAproxy：HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的web服务器不被暴露到网络上。
* heartbeat+ DRBD：
    heartbeat （Linux-HA）的工作原理：heartbeat最核心的包括两个部分，心跳监测部分和资源接管部分，心跳监测可以通过网络链路和串口进行，而且支持冗 余链路，它们之间相互发送报文来告诉对方自己当前的状态，如果在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运行在对方主机上的资源或者服务。
* Distributed Replicated Block Device(DRBD)是一个用软件实现的、无共享的、服务器之间镜像块设备内容的存储复制解决方案。
    数据镜像：实时、透明、同步（所有服务器都成功后返回）、异步（本地服务器成功后返回）

## 43. 占用进程
查看当前系统的状态：top
查看占用内存最大的5个进程：top，然后按M（大写）键。方法二：ps -aux | sort -k4nr | head -5

## 44. Linux系统的开机启动顺序，查询程序运行级别和修改运行级别
POST加电自检–》MBR引导–》GRUB–》加载内核–》启动init进程–》读取/etc/inittab文件，/etc/init/*.conf文件–》使用/etc/rc.d/rc.sysinit初始化脚本–》执行/etc/rc.d/rc脚本（加载/etc/rc3.d/下所有脚本）–》执行/etc/rc.d/rc.local–》执行/bin/login登录程序
查询程序运行级别：runlevel
修改运行级别：init [0123456]


## 45. 将192.168.16.3这台Windows的server文件夹挂载到linux本地/mnt/server目录，Windows的账户为：administrator，密码为：123456
    1. 先在windows下面共享需要挂载的目录server。
    2. 确保linux与windows是在同一个局域网当中。
    3. 在linux下面创建一个需要挂载到的目录/mnt/server。
    4. 利用mount命令进行挂载。
        挂载命令：mount -t cifs -o username=administrator,password=123456//192.168.16.3/server /mnt/server

## 46. mysql的innodb如何定位锁问题，mysql如何减少主从复制延迟
mysql的innodb如何定位锁问题:
    在使用 show engine innodb status检查引擎状态时，发现了死锁问题
    在5.5中，information_schema 库中增加了三个关于锁的表（MEMORY引擎）
    innodb_trx ## 当前运行的所有事务
    innodb_locks ## 当前出现的锁
    innodb_lock_waits ## 锁等待的对应关系

mysql如何减少主从复制延迟:
如果延迟比较大，就先确认以下几个因素：

    从库硬件比主库差，导致复制延迟
    主从复制单线程，如果主库写并发太大，来不及传送到从库，就会导致延迟。更高版本的mysql可以支持多线程复制
    慢SQL语句过多
    网络延迟
    master负载。主库读写压力大，导致复制延迟，架构的前端要加buffer及缓存层
    slave负载。一般的做法是，使用多台slave来分摊读请求，再从这些slave中取一台专用的服务器
    MySQL数据库主从同步延迟解决方案
    最简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行
    还有就是主库是写，对数据安全性较高，比如sync_binlog=1，innodb_flush_log_at_trx_commit
    = 1 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binlog
    innodb_flushlog也可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave

## 47. 如何重置mysql root密码？
    1、 在SHELL环境下，使用mysqladmin命令设置：
    mysqladmin –u root –p password “新密码” 回车后要求输入旧密码
    
    2、 在mysql>环境中,使用update命令，直接更新mysql库user表的数据：
    Update mysql.user set password=password(‘新密码’) where user=’root’;
    flush privileges;
    
    3、 在mysql>环境中，使用grant命令，修改root用户的授权权限。
    grant all on . to root@’localhost’ identified by ‘新密码’；

## 48. mysql数据备份工具
* mysqldump工具
    mysqldump是mysql自带的备份工具，目录在bin目录下面：/usr/local/mysql/bin/mysqldump
    支持基于innodb的热备份，但是由于是逻辑备份，所以速度不是很快，适合备份数据比较小的场景
    Mysqldump完全备份+二进制日志可以实现基于时间点的恢复。

* 基于LVM快照备份 
    在物理备份中，有基于文件系统的物理备份（LVM的快照），也可以直接用tar之类的命令对整个数据库目录
    进行打包备份，但是这些只能进行泠备份，不同的存储引擎备份的也不一样，myisam自动备份到表级别
    而innodb不开启独立表空间的话只能备份整个数据库。

* tar包备份
* percona提供的xtrabackup工具
    支持innodb的物理热备份，支持完全备份，增量备份，而且速度非常快，支持innodb存储引起的数据在不同
    数据库之间迁移，支持复制模式下的从机备份恢复备份恢复，为了让xtrabackup支持更多的功能扩展
    可以设立独立表空间，打开 innodb_file_per_table功能，启用之后可以支持单独的表备份
